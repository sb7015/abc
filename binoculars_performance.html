<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Binoculars Performance Metrics</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #EBE4FF 0%, #E1edff 100%);
            color: #231E33;
            line-height: 1.6;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, #5009B5 0%, #281849 100%);
            color: white;
            padding: 40px 20px;
            text-align: center;
            border-radius: 15px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(80, 9, 181, 0.3);
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .section {
            background: white;
            border-radius: 15px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.1);
        }

        .section-header {
            background: linear-gradient(90deg, #794CFF 0%, #00B5F5 100%);
            color: white;
            padding: 15px 25px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-size: 1.8em;
            font-weight: bold;
        }

        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .metric-card {
            background: linear-gradient(135deg, #EBE4FF 0%, #D9F5F5 100%);
            padding: 25px;
            border-radius: 12px;
            border-left: 5px solid #5009B5;
            transition: transform 0.3s ease;
        }

        .metric-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 20px rgba(80, 9, 181, 0.2);
        }

        .metric-card h3 {
            color: #5009B5;
            font-size: 1.3em;
            margin-bottom: 10px;
        }

        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
            color: #00BEBA;
            margin: 10px 0;
        }

        .metric-label {
            color: #231E33;
            font-size: 0.95em;
            opacity: 0.8;
        }

        .performance-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            overflow: hidden;
            border-radius: 10px;
        }

        .performance-table th {
            background: #5009B5;
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .performance-table td {
            padding: 15px;
            border-bottom: 1px solid #EBE4FF;
        }

        .performance-table tr:nth-child(even) {
            background: #F5F5F5;
        }

        .performance-table tr:hover {
            background: #EBE4FF;
        }

        .score-excellent {
            color: #00BEBA;
            font-weight: bold;
            font-size: 1.1em;
        }

        .score-good {
            color: #5009B5;
            font-weight: bold;
        }

        .score-moderate {
            color: #794CFF;
            font-weight: bold;
        }

        .score-low {
            color: #231E33;
            font-weight: bold;
            opacity: 0.6;
        }

        .comparison-box {
            background: linear-gradient(135deg, #281849 0%, #5009B5 100%);
            color: white;
            padding: 25px;
            border-radius: 12px;
            margin: 20px 0;
        }

        .comparison-box h3 {
            color: #00BEBA;
            margin-bottom: 15px;
        }

        .vs-table {
            width: 100%;
            margin-top: 15px;
        }

        .vs-table td {
            padding: 10px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .vs-table .method-name {
            color: #EBE4FF;
            font-weight: bold;
        }

        .vs-table .score {
            text-align: right;
            color: #00BEBA;
            font-size: 1.2em;
        }

        .highlight-box {
            background: #D9F5F5;
            border-left: 5px solid #00BEBA;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .warning-box {
            background: #EBE4FF;
            border-left: 5px solid #5009B5;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .chart-container {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border: 2px solid #EBE4FF;
        }

        .bar-chart {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin-top: 15px;
        }

        .bar-item {
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .bar-label {
            min-width: 150px;
            font-weight: bold;
            color: #231E33;
        }

        .bar-track {
            flex: 1;
            height: 30px;
            background: #F5F5F5;
            border-radius: 15px;
            overflow: hidden;
            position: relative;
        }

        .bar-fill {
            height: 100%;
            background: linear-gradient(90deg, #794CFF 0%, #00BEBA 100%);
            border-radius: 15px;
            display: flex;
            align-items: center;
            justify-content: flex-end;
            padding-right: 10px;
            color: white;
            font-weight: bold;
            transition: width 1s ease;
        }

        .dataset-badge {
            display: inline-block;
            background: #794CFF;
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            margin: 5px 5px 5px 0;
        }

        .key-finding {
            background: linear-gradient(135deg, #00BEBA 0%, #00B5F5 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            font-weight: 500;
        }

        .subsection {
            margin: 25px 0;
            padding: 20px;
            background: #F5F5F5;
            border-radius: 10px;
        }

        .subsection h3 {
            color: #5009B5;
            margin-bottom: 15px;
            font-size: 1.4em;
        }

        .stat-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 12px;
            background: white;
            margin: 8px 0;
            border-radius: 8px;
            border-left: 3px solid #00BEBA;
        }

        .stat-row strong {
            color: #5009B5;
        }

        .benchmark-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .benchmark-card {
            background: white;
            padding: 20px;
            border-radius: 10px;
            border: 2px solid #EBE4FF;
        }

        .benchmark-card h4 {
            color: #5009B5;
            margin-bottom: 10px;
        }

        code {
            background: #281849;
            color: #00BEBA;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
        }

        @media (max-width: 768px) {
            header h1 {
                font-size: 1.8em;
            }
            .section-header {
                font-size: 1.4em;
            }
            .metric-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>📊 Binoculars Performance Metrics</h1>
            <p>Comprehensive Evaluation & Benchmark Results</p>
            <p style="font-size: 0.9em; margin-top: 10px;">ICML 2024 | State-of-the-Art AI Text Detection</p>
        </header>

        <!-- Key Metrics Overview -->
        <div class="section">
            <div class="section-header">🎯 Key Performance Indicators</div>
            
            <div class="metric-grid">
                <div class="metric-card">
                    <h3>Primary Metric</h3>
                    <div class="metric-value">TPR @ 0.01% FPR</div>
                    <div class="metric-label">True Positive Rate at 0.01% False Positive Rate</div>
                </div>

                <div class="metric-card">
                    <h3>Best Performance</h3>
                    <div class="metric-value">97.6%</div>
                    <div class="metric-label">Student Essays Detection (ChatGPT)</div>
                </div>

                <div class="metric-card">
                    <h3>Average Detection</h3>
                    <div class="metric-value">90%+</div>
                    <div class="metric-label">Across Multiple Datasets & LLMs</div>
                </div>

                <div class="metric-card">
                    <h3>AUC Score</h3>
                    <div class="metric-value">0.998-1.0</div>
                    <div class="metric-label">Area Under ROC Curve</div>
                </div>
            </div>

            <div class="highlight-box">
                <strong>🔑 Why 0.01% FPR Matters:</strong> This metric prioritizes minimizing false accusations on human-written text. A 0.01% FPR means only 1 in 10,000 human texts is incorrectly flagged as AI-generated, which is crucial for real-world applications where falsely accusing humans has serious consequences.
            </div>
        </div>

        <!-- ChatGPT Detection Performance -->
        <div class="section">
            <div class="section-header">🤖 ChatGPT Detection Performance</div>
            
            <h3 style="color: #5009B5; margin-bottom: 15px;">Performance on Ghostbuster Dataset</h3>
            
            <table class="performance-table">
                <thead>
                    <tr>
                        <th>Dataset</th>
                        <th>TPR @ 0.01% FPR</th>
                        <th>F1 Score</th>
                        <th>AUC</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>News Articles</strong></td>
                        <td><span class="score-excellent">94.9%</span></td>
                        <td><span class="score-excellent">0.984</span></td>
                        <td><span class="score-excellent">0.999+</span></td>
                        <td>News stories generated by ChatGPT</td>
                    </tr>
                    <tr>
                        <td><strong>Creative Writing</strong></td>
                        <td><span class="score-excellent">93.5%</span></td>
                        <td><span class="score-excellent">0.991</span></td>
                        <td><span class="score-excellent">0.999+</span></td>
                        <td>Creative stories and narratives</td>
                    </tr>
                    <tr>
                        <td><strong>Student Essays</strong></td>
                        <td><span class="score-excellent">97.6%</span></td>
                        <td><span class="score-excellent">0.994</span></td>
                        <td><span class="score-excellent">1.000</span></td>
                        <td>Academic essays and assignments</td>
                    </tr>
                </tbody>
            </table>

            <div class="chart-container">
                <h4 style="color: #5009B5; margin-bottom: 10px;">ChatGPT Detection Rates (TPR @ 0.01% FPR)</h4>
                <div class="bar-chart">
                    <div class="bar-item">
                        <div class="bar-label">Student Essays</div>
                        <div class="bar-track">
                            <div class="bar-fill" style="width: 97.6%;">97.6%</div>
                        </div>
                    </div>
                    <div class="bar-item">
                        <div class="bar-label">News Articles</div>
                        <div class="bar-track">
                            <div class="bar-fill" style="width: 94.9%;">94.9%</div>
                        </div>
                    </div>
                    <div class="bar-item">
                        <div class="bar-label">Creative Writing</div>
                        <div class="bar-track">
                            <div class="bar-fill" style="width: 93.5%;">93.5%</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="key-finding">
                <strong>Key Finding:</strong> Binoculars achieves over 93% true positive rate across all ChatGPT-generated content types while maintaining an extremely low false positive rate of 0.01%, demonstrating robust performance across diverse writing styles.
            </div>

            <div class="chart-container">
                <h4 style="color: #5009B5; margin-bottom: 15px;">F1-Score Comparison: Binoculars vs. Competing Methods</h4>
                <img src="https://i.imgur.com/placeholder1.png" alt="F1-Score Comparison Chart" style="width: 100%; max-width: 900px; display: block; margin: 0 auto; border-radius: 8px;">
                <p style="margin-top: 10px; text-align: center; color: #231E33; opacity: 0.8;"><em>Binoculars consistently achieves F1-scores above 0.99 across all domains, significantly outperforming Ghostbuster (0.978-0.984), GPTZero (0.974-0.999), DetectGPT (0.534-0.720), and Zero-Shot methods (0.288-0.441).</em></p>
            </div>
        </div>

        <!-- Multi-LLM Performance -->
        <div class="section">
            <div class="section-header">🔄 Multi-LLM Detection Performance</div>
            
            <div class="subsection">
                <h3>LLaMA-2 and Falcon Detection</h3>
                <table class="performance-table">
                    <thead>
                        <tr>
                            <th>LLM</th>
                            <th>Dataset</th>
                            <th>TPR @ 0.01% FPR</th>
                            <th>AUC</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>LLaMA-2</strong></td>
                            <td>CCNews</td>
                            <td><span class="score-excellent">92-95%</span></td>
                            <td><span class="score-excellent">0.998</span></td>
                        </tr>
                        <tr>
                            <td><strong>LLaMA-2</strong></td>
                            <td>PubMed</td>
                            <td><span class="score-excellent">95-98%</span></td>
                            <td><span class="score-excellent">0.999</span></td>
                        </tr>
                        <tr>
                            <td><strong>Falcon</strong></td>
                            <td>CNN</td>
                            <td><span class="score-excellent">98-100%</span></td>
                            <td><span class="score-excellent">1.000</span></td>
                        </tr>
                        <tr>
                            <td><strong>Falcon</strong></td>
                            <td>Multi-domain</td>
                            <td><span class="score-excellent">95-99%</span></td>
                            <td><span class="score-excellent">0.999</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="subsection">
                <h3>GPT-3/4 Performance on Open-Orca Dataset</h3>
                <div class="benchmark-grid">
                    <div class="benchmark-card">
                        <h4>GPT-3 Detection</h4>
                        <div class="stat-row">
                            <span>True Positive Rate:</span>
                            <strong class="score-excellent">92.0%</strong>
                        </div>
                        <div class="stat-row">
                            <span>False Positive Rate:</span>
                            <strong>0.01%</strong>
                        </div>
                        <div class="stat-row">
                            <span>Dataset:</span>
                            <strong>Open-Orca</strong>
                        </div>
                    </div>

                    <div class="benchmark-card">
                        <h4>GPT-4 Detection</h4>
                        <div class="stat-row">
                            <span>True Positive Rate:</span>
                            <strong class="score-excellent">89.57%</strong>
                        </div>
                        <div class="stat-row">
                            <span>False Positive Rate:</span>
                            <strong>0.01%</strong>
                        </div>
                        <div class="stat-row">
                            <span>Dataset:</span>
                            <strong>Open-Orca</strong>
                        </div>
                    </div>
                </div>
            </div>

            <div class="highlight-box">
                <strong>💡 Cross-Model Generalization:</strong> Binoculars demonstrates strong zero-shot generalization across different LLM architectures (ChatGPT, GPT-3/4, LLaMA-2, Falcon) without requiring model-specific training, proving its robustness and versatility.
            </div>
        </div>

        <!-- Multi-lingual Performance -->
        <div class="section">
            <div class="section-header">🌍 Multi-lingual Performance (M4 Dataset)</div>
            
            <table class="performance-table">
                <thead>
                    <tr>
                        <th>Language/Domain</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>Notes</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>English</strong></td>
                        <td><span class="score-excellent">80-100%</span></td>
                        <td><span class="score-excellent">High</span></td>
                        <td>Strong performance across all English domains</td>
                    </tr>
                    <tr>
                        <td><strong>German</strong></td>
                        <td><span class="score-good">70-90%</span></td>
                        <td><span class="score-good">Medium-High</span></td>
                        <td>Good performance on Germanic languages</td>
                    </tr>
                    <tr>
                        <td><strong>French</strong></td>
                        <td><span class="score-good">70-85%</span></td>
                        <td><span class="score-good">Medium</span></td>
                        <td>Moderate performance on Romance languages</td>
                    </tr>
                    <tr>
                        <td><strong>Arabic</strong></td>
                        <td><span class="score-moderate">60-90%</span></td>
                        <td><span class="score-low">1-2%</span></td>
                        <td>High precision but very low recall</td>
                    </tr>
                    <tr>
                        <td><strong>Chinese</strong></td>
                        <td><span class="score-moderate">65-85%</span></td>
                        <td><span class="score-low">Low</span></td>
                        <td>Limited performance on non-Latin scripts</td>
                    </tr>
                </tbody>
            </table>

            <div class="warning-box">
                <strong>⚠️ Language Limitation:</strong> Binoculars performs best on English text. Performance degrades for non-English languages, especially those with non-Latin scripts or low-resource languages. This is due to model biases in the underlying Falcon models, which are primarily trained on English data.
            </div>
        </div>

        <!-- Robustness Tests -->
        <div class="section">
            <div class="section-header">🛡️ Robustness & Edge Cases</div>
            
            <div class="subsection">
                <h3>Style-Modified Prompts</h3>
                <div class="stat-row">
                    <span>Test: Style modifications (e.g., "pirate slang", "Shakespearean")</span>
                    <strong class="score-excellent">False Negative Rate: < 6%</strong>
                </div>
                <div class="stat-row">
                    <span>Robustness to prompt variations:</span>
                    <strong class="score-excellent">94%+ accuracy maintained</strong>
                </div>
            </div>

            <div class="subsection">
                <h3>Non-Native English Essays</h3>
                <div class="stat-row">
                    <span>Test: Essays written by non-native English speakers</span>
                    <strong class="score-excellent">99.67% accuracy</strong>
                </div>
                <div class="stat-row">
                    <span>Bias assessment:</span>
                    <strong class="score-excellent">Unbiased detection</strong>
                </div>
                <p style="margin-top: 10px; color: #231E33; opacity: 0.8;">Binoculars does not discriminate against non-native English writing, maintaining high accuracy without bias.</p>

                <div class="chart-container" style="margin-top: 20px;">
                    <h4 style="color: #5009B5; margin-bottom: 15px;">Essay Forum: Score Distribution Analysis</h4>
                    <img src="https://i.imgur.com/placeholder2.png" alt="Essay Forum Score Distribution" style="width: 100%; max-width: 800px; display: block; margin: 0 auto; border-radius: 8px;">
                    <p style="margin-top: 10px; text-align: center; color: #231E33; opacity: 0.8;"><em>Distribution of Binoculars scores on Essay Forum dataset showing clear separation between original essays and corrected essays around the optimal threshold of 0.901. The overlapping distributions demonstrate robustness to grammatical corrections while maintaining detection capability.</em></p>
                </div>
            </div>

            <div class="subsection">
                <h3>Memorized Text Detection</h3>
                <div class="benchmark-card">
                    <h4>Famous Passages (e.g., US Constitution)</h4>
                    <p style="margin: 10px 0;">Binoculars classifies memorized text as <strong style="color: #5009B5;">machine-generated</strong> if it's likely that LLMs reproduced it from training data.</p>
                    <div class="warning-box" style="margin-top: 10px;">
                        <strong>Note:</strong> This is expected behavior. Memorized passages that LLMs reproduce verbatim should be flagged since they exhibit the same statistical patterns as AI-generated text.
                    </div>
                </div>
            </div>

            <div class="subsection">
                <h3>Document Length Performance</h3>
                <div class="chart-container">
                    <h4 style="color: #5009B5; margin-bottom: 10px;">TPR vs. Document Length (tokens)</h4>
                    <div class="bar-chart">
                        <div class="bar-item">
                            <div class="bar-label">128 tokens</div>
                            <div class="bar-track">
                                <div class="bar-fill" style="width: 85%;">85-90%</div>
                            </div>
                        </div>
                        <div class="bar-item">
                            <div class="bar-label">256 tokens</div>
                            <div class="bar-track">
                                <div class="bar-fill" style="width: 92%;">92-95%</div>
                            </div>
                        </div>
                        <div class="bar-item">
                            <div class="bar-label">512 tokens</div>
                            <div class="bar-track">
                                <div class="bar-fill" style="width: 95%;">95-98%</div>
                            </div>
                        </div>
                        <div class="bar-item">
                            <div class="bar-label">1024+ tokens</div>
                            <div class="bar-track">
                                <div class="bar-fill" style="width: 97%;">97%+</div>
                            </div>
                        </div>
                    </div>
                    <p style="margin-top: 15px; color: #231E33; opacity: 0.8;"><strong>Optimal Range:</strong> 128-512 tokens provide strong performance. Longer documents generally yield higher accuracy.</p>
                </div>
            </div>
        </div>

        <!-- Comparison with Other Methods -->
        <div class="section">
            <div class="section-header">⚔️ Comparison with State-of-the-Art Detectors</div>
            
            <div class="comparison-box">
                <h3>Binoculars vs. Competing Methods</h3>
                <p style="opacity: 0.9; margin-bottom: 15px;">Performance comparison on ChatGPT detection (TPR @ 0.01% FPR)</p>
                
                <table class="vs-table">
                    <tr>
                        <td class="method-name">🏆 Binoculars</td>
                        <td class="score">93.5-97.6%</td>
                    </tr>
                    <tr>
                        <td class="method-name">Ghostbuster (OOD)</td>
                        <td class="score" style="color: #794CFF;">50.5-99.1%</td>
                    </tr>
                    <tr>
                        <td class="method-name">GPTZero</td>
                        <td class="score" style="color: #794CFF;">64.7-96.6%</td>
                    </tr>
                    <tr>
                        <td class="method-name">DetectGPT</td>
                        <td class="score" style="color: rgba(255,255,255,0.5);">1-4.5%</td>
                    </tr>
                    <tr>
                        <td class="method-name">Fast-DetectGPT</td>
                        <td class="score" style="color: rgba(255,255,255,0.5);">0.4-0.7%</td>
                    </tr>
                    <tr>
                        <td class="method-name">DNA-GPT</td>
                        <td class="score" style="color: rgba(255,255,255,0.5);">0-1%</td>
                    </tr>
                </table>
            </div>

            <div class="key-finding">
                <strong>🎯 Competitive Advantage:</strong> Binoculars significantly outperforms all tested competitors, especially perturbation-based methods like DetectGPT (1-4.5%) and Fast-DetectGPT (0.4-0.7%), while maintaining zero-shot capability without requiring labeled training data.
            </div>

            <div class="chart-container" style="margin-top: 25px;">
                <h4 style="color: #5009B5; margin-bottom: 15px;">ROC Curves: True Positive Rate vs. False Positive Rate</h4>
                <img src="https://i.imgur.com/placeholder3.png" alt="ROC Curves Comparison" style="width: 100%; max-width: 1000px; display: block; margin: 0 auto; border-radius: 8px;">
                <p style="margin-top: 10px; text-align: center; color: #231E33; opacity: 0.8;"><em>ROC curves across three datasets (PubMed, CC News, CNN) demonstrate Binoculars' superior performance with consistently higher true positive rates at extremely low false positive rates. Binoculars (red) dominates all other methods across the entire spectrum, achieving near-perfect AUC scores of 0.998-1.0.</em></p>
            </div>

            <div class="subsection">
                <h3>Why Binoculars Outperforms Others</h3>
                <ul style="margin-left: 20px; line-height: 2;">
                    <li><strong>Zero-shot:</strong> No training data required, unlike supervised methods</li>
                    <li><strong>Prompt-invariant:</strong> Robust to various prompt styles and modifications</li>
                    <li><strong>Cross-perplexity ratio:</strong> Normalizes for topic and prompt effects</li>
                    <li><strong>Model alignment detection:</strong> Leverages shared training data patterns across LLMs</li>
                    <li><strong>Fixed threshold:</strong> Single global threshold (0.901) works across all domains</li>
                </ul>
            </div>
        </div>

        <!-- Datasets Used -->
        <div class="section">
            <div class="section-header">📚 Evaluation Datasets</div>
            
            <div class="benchmark-grid">
                <div class="benchmark-card">
                    <h4>Ghostbuster Dataset</h4>
                    <div class="dataset-badge">News</div>
                    <div class="dataset-badge">Creative Writing</div>
                    <div class="dataset-badge">Student Essays</div>
                    <p style="margin-top: 10px;">ChatGPT-generated content across three domains with human-written counterparts.</p>
                </div>

                <div class="benchmark-card">
                    <h4>Domain-Specific Datasets</h4>
                    <div class="dataset-badge">CCNews</div>
                    <div class="dataset-badge">PubMed</div>
                    <div class="dataset-badge">CNN</div>
                    <p style="margin-top: 10px;">News articles and medical abstracts from various sources.</p>
                </div>

                <div class="benchmark-card">
                    <h4>Open-Orca Dataset</h4>
                    <div class="dataset-badge">GPT-3</div>
                    <div class="dataset-badge">GPT-4</div>
                    <p style="margin-top: 10px;">Instruction-following datasets generated by OpenAI models.</p>
                </div>

                <div class="benchmark-card">
                    <h4>M4 Multi-lingual Dataset</h4>
                    <div class="dataset-badge">English</div>
                    <div class="dataset-badge">German</div>
                    <div class="dataset-badge">French</div>
                    <div class="dataset-badge">Arabic</div>
                    <div class="dataset-badge">Chinese</div>
                    <p style="margin-top: 10px;">Multi-lingual and multi-domain evaluation across 5+ languages.</p>
                </div>
            </div>
        </div>

        <!-- Performance Summary -->
        <div class="section">
            <div class="section-header">📈 Performance Summary</div>
            
            <div class="subsection">
                <h3>Strengths</h3>
                <div class="stat-row">
                    <span>✅ High accuracy on English text</span>
                    <strong class="score-excellent">90%+ TPR across domains</strong>
                </div>
                <div class="stat-row">
                    <span>✅ Very low false positive rate</span>
                    <strong class="score-excellent">0.01% (1 in 10,000)</strong>
                </div>
                <div class="stat-row">
                    <span>✅ Zero-shot capability</span>
                    <strong class="score-excellent">No training data needed</strong>
                </div>
                <div class="stat-row">
                    <span>✅ Cross-model generalization</span>
                    <strong class="score-excellent">Works on ChatGPT, GPT-3/4, LLaMA, Falcon</strong>
                </div>
                <div class="stat-row">
                    <span>✅ Prompt-invariant</span>
                    <strong class="score-excellent">< 6% FNR on style variations</strong>
                </div>
            </div>

            <div class="subsection">
                <h3>Limitations</h3>
                <div class="stat-row">
                    <span>⚠️ Language coverage</span>
                    <strong>Best for English; weaker on other languages</strong>
                </div>
                <div class="stat-row">
                    <span>⚠️ Document length</span>
                    <strong>Optimal: 128-512 tokens; weaker on very short texts</strong>
                </div>
                <div class="stat-row">
                    <span>⚠️ Memorized content</span>
                    <strong>May flag verbatim reproductions from training data</strong>
                </div>
                <div class="stat-row">
                    <span>⚠️ Model coverage</span>
                    <strong>Tested on models < 30B parameters</strong>
                </div>
            </div>

            <div class="key-finding">
                <strong>🎓 Research Impact:</strong> Binoculars represents state-of-the-art performance in zero-shot AI text detection, with consistently high accuracy across diverse datasets, domains, and LLM architectures, making it a valuable tool for academic research, content moderation, and AI ethics applications.
            </div>
        </div>

        <!-- Footer -->
        <div style="text-align: center; padding: 40px 20px; color: #231E33;">
            <p style="font-size: 1.1em; margin-bottom: 10px;"><strong>Paper:</strong> "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text"</p>
            <p style="font-size: 0.9em; opacity: 0.7;">Abhimanyu Hans et al. | ICML 2024 | arXiv:2401.12070</p>
            <p style="font-size: 0.9em; opacity: 0.7; margin-top: 10px;">GitHub: ahans30/Binoculars | Free & Open Source</p>
        </div>
    </div>
</body>
</html>